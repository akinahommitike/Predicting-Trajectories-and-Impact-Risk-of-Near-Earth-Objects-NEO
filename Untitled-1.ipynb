{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                 name  est_diameter_min  est_diameter_max  \\\n",
      "0       2162635  162635 (2000 SS164)          1.198271          2.679415   \n",
      "1       2277475    277475 (2005 WK4)          0.265800          0.594347   \n",
      "2       2512244   512244 (2015 YE18)          0.722030          1.614507   \n",
      "3       3596030          (2012 BV13)          0.096506          0.215794   \n",
      "4       3667127          (2014 GE35)          0.255009          0.570217   \n",
      "...         ...                  ...               ...               ...   \n",
      "90831   3763337           (2016 VX1)          0.026580          0.059435   \n",
      "90832   3837603           (2019 AD3)          0.016771          0.037501   \n",
      "90833  54017201           (2020 JP3)          0.031956          0.071456   \n",
      "90834  54115824           (2021 CN5)          0.007321          0.016370   \n",
      "90835  54205447           (2021 TW7)          0.039862          0.089133   \n",
      "\n",
      "       relative_velocity  miss_distance orbiting_body  sentry_object  \\\n",
      "0           13569.249224   5.483974e+07         Earth          False   \n",
      "1           73588.726663   6.143813e+07         Earth          False   \n",
      "2          114258.692129   4.979872e+07         Earth          False   \n",
      "3           24764.303138   2.543497e+07         Earth          False   \n",
      "4           42737.733765   4.627557e+07         Earth          False   \n",
      "...                  ...            ...           ...            ...   \n",
      "90831       52078.886692   1.230039e+07         Earth          False   \n",
      "90832       46114.605073   5.432121e+07         Earth          False   \n",
      "90833        7566.807732   2.840077e+07         Earth          False   \n",
      "90834       69199.154484   6.869206e+07         Earth          False   \n",
      "90835       27024.455553   5.977213e+07         Earth          False   \n",
      "\n",
      "       absolute_magnitude  hazardous  \n",
      "0                   16.73      False  \n",
      "1                   20.00       True  \n",
      "2                   17.83      False  \n",
      "3                   22.20      False  \n",
      "4                   20.09       True  \n",
      "...                   ...        ...  \n",
      "90831               25.00      False  \n",
      "90832               26.00      False  \n",
      "90833               24.60      False  \n",
      "90834               27.80      False  \n",
      "90835               24.12      False  \n",
      "\n",
      "[90836 rows x 10 columns]\n",
      "X_train_scaled shape: (27251, 9)\n",
      "y_train shape: (63585,)\n",
      "X_test_scaled shape: (27251, 9)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [27251, 63585]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#Logistic Regression\u001b[39;00m\n\u001b[1;32m     31\u001b[0m log\u001b[38;5;241m=\u001b[39mLogisticRegression()\n\u001b[0;32m---> 32\u001b[0m \u001b[43mlog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m y_log_predict\u001b[38;5;241m=\u001b[39mlog\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#Linear_Discriminant_Analysis\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1291\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1273\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1274\u001b[0m     X,\n\u001b[1;32m   1275\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1287\u001b[0m )\n\u001b[1;32m   1289\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1291\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:460\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    458\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    463\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [27251, 63585]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, classification_report\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "df=pd.read_csv(\"neo.csv\")\n",
    "print(df)\n",
    "encoded_df = pd.get_dummies(df[\"hazardous\"])\n",
    "X=df.drop('absolute_magnitude',axis=1)\n",
    "y=df['absolute_magnitude']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "# Replace non-numeric values with NaN\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0)  # Replace with 0 or any other value\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Initialize StandardScaler and fit-transform on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Use transform only on test set\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "#Logistic Regression\n",
    "log=LogisticRegression()\n",
    "log.fit(X_train_scaled,y_train)\n",
    "y_log_predict=log.predict(X_test)\n",
    "#Linear_Discriminant_Analysis\n",
    "lda=LDA()\n",
    "lda.fit(X_train_scaled,y_train)\n",
    "#Quadratic_Discriminant_Analysis\n",
    "qda=QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train_scaled,y_train)\n",
    "#Lasso\n",
    "las=Lasso(alpha=0.1)\n",
    "las.fit(X_train_scaled,y_train)\n",
    "#RidgeCV\n",
    "ridge=RidgeCV(alpha=0.4)\n",
    "ridge.fit(X_train,y_train)\n",
    "# Predictions\n",
    "y_log_predict = log.predict(X_test_scaled)\n",
    "y_lda_predict = lda.predict(X_test_scaled)\n",
    "y_qda_predict = qda.predict(X_test_scaled)\n",
    "y_las_predict = las.predict(X_test_scaled)\n",
    "y_ridge_predict = ridge.predict(X_test_scaled)\n",
    "#Evaluate\n",
    "# Compute confusion matrix for Logistic Regression\n",
    "cm_log = confusion_matrix(y_test, y_log_predict)\n",
    "print(\"Confusion Matrix for Logistic Regression:\")\n",
    "print(cm_log)\n",
    "\n",
    "# Compute confusion matrix for Linear Discriminant Analysis\n",
    "cm_lda = confusion_matrix(y_test, y_lda_predict)\n",
    "print(\"\\nConfusion Matrix for Linear Discriminant Analysis:\")\n",
    "print(cm_lda)\n",
    "\n",
    "# Compute confusion matrix for Quadratic Discriminant Analysis\n",
    "cm_qda = confusion_matrix(y_test, y_qda_predict)\n",
    "print(\"\\nConfusion Matrix for Quadratic Discriminant Analysis:\")\n",
    "print(cm_qda)\n",
    "# Display confusion matrix using ConfusionMatrixDisplay (optional)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_log, display_labels=log.classes_)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "#ROC AND AUC\n",
    "# Logistic Regression\n",
    "fpr_log, tpr_log, _ = roc_curve(y_test, log.predict_proba(X_test_scaled)[:, 1])\n",
    "roc_auc_log = auc(fpr_log, tpr_log)\n",
    "\n",
    "# LDA\n",
    "fpr_lda, tpr_lda, _ = roc_curve(y_test, lda.predict_proba(X_test_scaled)[:, 1])\n",
    "roc_auc_lda = auc(fpr_lda, tpr_lda)\n",
    "\n",
    "# QDA\n",
    "fpr_qda, tpr_qda, _ = roc_curve(y_test, qda.predict_proba(X_test_scaled)[:, 1])\n",
    "roc_auc_qda = auc(fpr_qda, tpr_qda)\n",
    "#Visualization for evaluation matrix\n",
    "#Confusion matrix Heatmap Function\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {title}')\n",
    "    plt.show()\n",
    "plot_confusion_matrix(cm_log, 'Logistic Regression')\n",
    "plot_confusion_matrix(cm_lda, 'Linear Discriminant Analysis')\n",
    "plot_confusion_matrix(cm_qda, 'Quadratic Discriminant Analysis')\n",
    "\n",
    "# ROC and AUC Visualization\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr_log, tpr_log, color='darkorange', lw=2, label='ROC curve (area = %0.2f) [Logistic Regression]' % roc_auc_log)\n",
    "plt.plot(fpr_lda, tpr_lda, color='blue', lw=2, label='ROC curve (area = %0.2f) [LDA]' % roc_auc_lda)\n",
    "plt.plot(fpr_qda, tpr_qda, color='green', lw=2, label='ROC curve (area = %0.2f) [QDA]' % roc_auc_qda)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
